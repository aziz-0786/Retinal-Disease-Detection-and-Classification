# -*- coding: utf-8 -*-
"""retinal_disease_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x9FYlGGBbVPYwpUY1kcCCuFX0f7pGxzc
"""

!pip install tensorflow-cpu keras numpy pandas matplotlib seaborn opencv-python scikit-learn

import tensorflow as tf
print(f"TensorFlow version: {tf.__version__}")
print(f"TensorFlow is built with CUDA: {tf.test.is_built_with_cuda()}")
print(f"GPUs available: {tf.config.list_physical_devices('GPU')}")

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import os
import cv2

!rm -f /content/dataset.zip

!unzip /content/dataset.zip -d /content/

!ls /content/dataset/

#  Configuration
DATA_DIR = 'dataset'
NUM_CLASSES = 4
CLASS_NAMES = ['normal', 'cataract', 'glaucoma', 'diabetic_retinopathy']

IMAGE_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 50
DATA_DIR = 'dataset'
NUM_CLASSES = 4
CLASS_NAMES = ['normal', 'cataract', 'glaucoma', 'diabetic_retinopathy']

# Function to load images and labels
def load_images_from_folder(folder, label):
    images = []
    labels = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        try:
            # Read image using OpenCV
            img = cv2.imread(img_path)
            if img is not None:
                # Resize image
                img = cv2.resize(img, IMAGE_SIZE)
                # Normalize pixel values to [0, 1]
                img = img / 255.0
                images.append(img)
                labels.append(label)
            else:
                print(f"Warning: Could not read image {img_path}")
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
    return images, labels

all_images = []
all_labels = []

# Load images for each class
for class_name in CLASS_NAMES:
    folder_path = os.path.join(DATA_DIR, class_name)
    if os.path.exists(folder_path):
        print(f"Loading images from: {folder_path}")
        images, labels = load_images_from_folder(folder_path, class_name)
        all_images.extend(images)
        all_labels.extend(labels)
    else:
        print(f"Error: Directory not found for class '{class_name}': {folder_path}")
        print("Please ensure your dataset is structured as 'dataset/normal', 'dataset/cataract', etc.")
        continue

if not all_images:
    print("No images loaded. Please ensure your 'dataset' folder is correctly uploaded or mounted and subfolder names match casing.")
    exit()

X = np.array(all_images)
y_labels = np.array(all_labels)

print(f"Total images loaded: {len(X)}")
print(f"Shape of image data (X): {X.shape}")
print(f"Shape of labels (y_labels): {y_labels.shape}")

# Encode labels to numerical format
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_labels)
print(f"Encoded labels: {y[:5]} (e.g., {label_encoder.inverse_transform(y[:5])})")
print(f"Classes mapping: {list(label_encoder.classes_)}")

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"Data split into X_train: {X_train.shape}, X_test: {X_test.shape}")
print(f"Labels split into y_train: {y_train.shape}, y_test: {y_test.shape}")

# Data Augmentation for Image Data

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Fit data generator to training data
datagen.fit(X_train)

# Build the CNN Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5), # Dropout for regularization
    Dense(NUM_CLASSES, activation='softmax') # Output layer with NUM_CLASSES neurons for classification
])

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='sparse_categorical_crossentropy', # Use sparse_categorical_crossentropy for integer labels
              metrics=['accuracy'])

model.summary()

# Train the Model
history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
                    epochs=EPOCHS,
                    validation_data=(X_test, y_test),
                    verbose=1)

# Plot training history
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

#Evaluate the Model
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
y_pred_proba = model.predict(X_test)
y_pred = np.argmax(y_pred_proba, axis=1)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()
print("\nConfusion Matrix:\n", cm)

# Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

#  Demonstrate Prediction on a Sample Image
sample_index = np.random.randint(0, len(X_test))
sample_image = X_test[sample_index]
true_label_encoded = y_test[sample_index]
true_label_name = label_encoder.inverse_transform([true_label_encoded])[0]

# Reshape for model prediction (add batch dimension)
sample_image_for_prediction = np.expand_dims(sample_image, axis=0)

# Make prediction
prediction_proba = model.predict(sample_image_for_prediction)[0]
predicted_label_encoded = np.argmax(prediction_proba)
predicted_label_name = label_encoder.inverse_transform([predicted_label_encoded])[0]

print(f"Sample Image True Label: {true_label_name}")
print(f"Sample Image Predicted Label: {predicted_label_name}")
print(f"Prediction Probabilities: {prediction_proba}")

# Display the sample image
plt.figure(figsize=(4, 4))
plt.imshow(sample_image)
plt.title(f"True: {true_label_name}\nPredicted: {predicted_label_name} ({prediction_proba[predicted_label_encoded]*100:.2f}%)")
plt.axis('off')
plt.show()